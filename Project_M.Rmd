---
title: "Prediction Assignment Writeup"
author: "M"
date: "4/11/2020"
output: html_document
---


Using devices such as Jawbone Up, Nike FuelBand, and Fitbit, it is now possible to collect a large amount of data about personal activity relatively inexpensively. The aim of this project is to predict the manner in which participants perform a barbell lift. The data comes from http://groupware.les.inf.puc-rio.br/har wherein 6 participants were asked to perform the same set of exercises correctly and incorrectly with accelerometers placed on the belt, forearm, arm, and dumbell.  

For the purpose of this project, the following steps would be followed:

1. Data Preprocessing
2. Exploratory Analysis
3. Prediction Model Selection
4. Predicting Test Set Output

## Data Preprocessing 

First, we load the training and testing set from the online sources and then split the training set further into training and test sets. 

```{r DataLoading, message = FALSE}
library(caret)

trainURL <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testURL <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train <- read.csv(url(trainURL))
test <- read.csv(url(testURL))
label <- createDataPartition(train$classe, p = 0.7, list = FALSE)
train <- train[label, ]
test <- train[-label, ]
```

From among 160 variables present in the dataset, some variables have nearly zero variance whereas some contain a lot of NA terms which need to be excluded from the dataset. Moreover, other 5 variables used for identification can also be removed. 



What we see is a lot of data with NA / empty values. Let's remove those


```{r DataCleaning}

library(caret)
NZV <- nearZeroVar(train)
train <- train[ ,-NZV]
test <- test[ ,-NZV]
label <- apply(train, 2, function(x) mean(is.na(x))) > 0.95
train <- train[, -which(label, label == FALSE)]
test <- test[, -which(label, label == FALSE)]
train <- train[ , -(1:5)]
test <- test[ , -(1:5)]
```

As a result of the preprocessing steps, we were able to reduce 160 variables to 54.


## Exploratory Analysis

Now that we have cleaned the dataset off absolutely useless varibles, we shall look at the dependence of these variables on each other through a correlation plot. 

```{r CorrelationPlot, fig.width=12, fig.height=8}
library(corrplot)
corrMat <- cor(train[,-54])
corrplot(corrMat, method = "color", type = "lower", tl.cex = 0.8, tl.col = rgb(0,0,0))
```

In the plot above, darker gradient correspond to having high correlation. A Principal Component Analysis can be run to further reduce the dimension of our dataset.



## Prediction Model Selection


We will fit 3 methods to model our data. We will choose the better one after testing the best accuracy.

A confusion matrix plotted at the end of each model will help visualize the analysis better.

### Decision Tree

```{r DecisionTree, message = FALSE, warning = FALSE, fig.width=18, fig.height=10}
library(rpart)
library(rpart.plot)
#install.packages("rattle")
library(rattle)
set.seed(13908)
modelDT <- rpart(classe ~ ., data = train, method = "class")
fancyRpartPlot(modelDT)
predictDT <- predict(modelDT, test, type = "class")
#install.packages("e1071")
library(e1071)
confMatDT <- confusionMatrix(predictDT, test$classe)
confMatDT
```


### Random Forest

```{r RandomForest, message = FALSE}
library(caret)
set.seed(13908)
control <- trainControl(method = "cv", number = 3, verboseIter=FALSE)
modelRF <- train(classe ~ ., data = train, method = "rf", trControl = control)
modelRF$finalModel
predictRF <- predict(modelRF, test)
confMatRF <- confusionMatrix(predictRF, test$classe)
confMatRF
```

### Generalized Boosted Model

```{r GBM, message = FALSE}
library(caret)
set.seed(13908)
control <- trainControl(method = "repeatedcv", number = 5, repeats = 1, verboseIter = FALSE)
modelGBM <- train(classe ~ ., data = train, trControl = control, method = "gbm", verbose = FALSE)
modelGBM$finalModel
predictGBM <- predict(modelGBM, test)
confMatGBM <- confusionMatrix(predictGBM, test$classe)
confMatGBM
```

As Random Forest offers the maximum accuracy of 100.00%. We could have a little problem of overfitting.We can note this when we have this perfect confusion matrix. We select the GBM Model.

## Predicting Test Set Output

```{r TestSetPrediction, messages = FALSE}

predictGBM <- predict(modelGBM, test)
#predictGBM

```

## Using Cross Validation
Using the tecnique of Cross Validation to prevent the overfitting.

#### Random forest

##### Model

```{r}
controlRf <- trainControl(method="cv", 5, allowParallel = TRUE)
modelRf <- train(classe ~ ., data=train, method="rf", trControl=controlRf, ntree=100)
#modelRf
```

##### Performance of the model on the test set

```{r}
predict_rf <- predict(modelRf, test)
confusionMatrix(test$classe, predict_rf)
```

Accurate model to classify **classe** feature. Maybe we have overfit.

#### XGBoost

```{r}
controlXGB <- trainControl(method="cv", 5, allowParallel = TRUE)
modelXGB <- train(classe ~ ., data=train, method="xgbTree", trControl=controlXGB)
```

```{r}
#modelXGB
```

##### Performance of the model on the test set

```{r}
predict_XGB <- predict(modelXGB, test)
confusionMatrix(test$classe, predict_XGB)
```

With XGB we reach a better accuracy on test data.

### Compare models

```{r}
# collect resamples
model_results <- resamples(list(RF=modelRf, XGB=modelXGB))
# summarize the distributions
summary(model_results)
# boxplots of results
bwplot(model_results)
# dot plots of results
dotplot(model_results)
```

